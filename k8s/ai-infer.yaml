apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-infer-service
spec:
  replicas: 1
  selector:
    matchLabels: { app: ai-infer-service }
  template:
    metadata:
      labels: { app: ai-infer-service }
    spec:
      containers:
        - name: service
          image: ai-infer:latest
          imagePullPolicy: IfNotPresent
          ports: [{ containerPort: 8080 }]
          readinessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 3
          livenessProbe:
            httpGet: { path: /healthz, port: 8080 }
            initialDelaySeconds: 10
          resources:
            requests: { cpu: "10m", memory: "64Mi" }
            limits:   { cpu: "500m", memory: "256Mi" }
---
apiVersion: v1
kind: Service
metadata:
  name: ai-infer-service
spec:
  selector: { app: ai-infer-service }
  ports:
    - name: http
      port: 8080
      targetPort: 8080
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-loadgen
spec:
  replicas: 1
  selector:
    matchLabels: { app: ai-loadgen }
  template:
    metadata:
      labels: { app: ai-loadgen }
    spec:
      containers:
        - name: loadgen
          image: ai-loadgen:latest
          imagePullPolicy: IfNotPresent
          env:
            - { name: SERVICE_URL, value: "http://ai-infer-service:8080" }
            - { name: QPS, value: "200" }
            - { name: CONCURRENCY, value: "60" }
          ports: [{ containerPort: 9090 }]
---
apiVersion: v1
kind: Service
metadata:
  name: ai-loadgen
spec:
  selector: { app: ai-loadgen }
  ports:
    - name: http
      port: 9090
      targetPort: 9090
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-infer-service
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-infer-service
  minReplicas: 1
  maxReplicas: 5
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 20
